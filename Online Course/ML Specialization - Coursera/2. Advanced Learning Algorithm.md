#lecture/coursera #DL/CNN #ML/decision-tree  #ML/ensemble
## Neural Network
### Basic Concepts
- Input(data) -> Computation(layers) -> Output 구조
- 이전 layer의 Output이 다음 layer의 Input으로 연결(chain)
- 각 layer의 Output은 Vectorization 필요
- Forward Propagation: 정방향 연산 특성
![[../../../9. AttachedFiles/Pasted image 20250224043046.png]]

### TensorFlow
- Neural Network 구축을 위한 도구
- Keras, Utility, Optimizer, Regularization 함수 제공
- 자동 미분 지원으로 효율적인 Back-propagation 구현
- 모델 구성: Sequential([Dense(..), Dense(..), ..])

## Neural Network Training
### Activation Functions
- Binary Classification: Sigmoid
- Boundary Classification: Linear, non-Linear
- 양수 값 필요 시: ReLU(Rectified Linear Unit)

![[../../../9. AttachedFiles/Pasted image 20250224043116.png]]

### Multi-class Classification
- Softmax: 다중/비선형 경계 처리 가능
- Logistic Regression: z=w*x+b
- Cross-entropy loss 사용

### Advanced Techniques
- Adam(Adaptive Mnist): 경사하강법 최적화
- 학습 중 learning rate 조정
	![[../../../9. AttachedFiles/Pasted image 20250224043214.png]]
### CNN (Convolutional Neural Network)
- DNN의 문제: 이미지 평탄화로 공간/위상 정보 손실
- 해결책: 부분 이미지 사용으로 공간 위상 정보 유지
- 장점: 빠른 계산, 적은 학습 데이터 필요

### Back Propagation
- 다층 신경망에서 미분 활용
- Chain rule로 계산 과정 단순화
- 계산 시간 개선: N(Node) + N(parameter)

## Machine Learning Tips
### Model Tuning
- Feature, learning rate, 학습 데이터 크기 조정
- Cross-validation으로 학습 오차 추정

### Bias and Variance
![[../../../9. AttachedFiles/Pasted image 20250224043319.png|350]]
- Bias: mean(Prediction - Real)
- Underfitting과 overfitting 사이 최적점 탐색
- 개선 방법: 샘플 크기, 특성 집합, 정규화 조정
![[../../../9. AttachedFiles/Pasted image 20250224043415.png|600]]

### Model Evaluation
- Confusion matrix, Precision-recall, F1-score 활용
$$
Accuracy = (TP + TN)/(TP + FP + FN + FN), \ Precision = TP / (TP + FP), \ Recall = TP / (TP + FN), \ F1 = 2 * Precision * Recall / (Precision + Recall)
$$
## Decision Trees
### Classification Tree
- 범주형 목표값 처리
- CART(Classification And Regression Tree) 모델
- Gini Criterion 기반 특성 분할
- 높은 깊이로 순도 향상
- NP-complete 문제: 최적 경계 탐색의 어려움

### Regression Tree
- 연속형 목표값 처리
- 이진 재귀 분할 프로세스
- Pros : 비선형 데이터 적합, EDA 불필요
- Cons : 과적합 취약, 낮은 예측 점수

### Advanced Tree Techniques
- Encoding: 비이진 특성 처리
  - Target encoding: 중앙값 사용
  - One-hot encoding: 클래스를 숫자로 변환

### Ensemble Methods
- Random Forest: 샘플 데이터의 중앙값 사용
- Bagging: 비복원 추출, 분할 정복
- Boosting: 복원 추출 (AdaBoost, Gradient Boosting, XGBoost)

### Neural Network vs Decision Tree
- Decision Tree: 구조화된 데이터에 적합
- Neural Network: 
	  - 구조화/비구조화 데이터 모두 처리
	  - 느린 학습 속도 & 쉬운 모델 확장성